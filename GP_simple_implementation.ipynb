{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c068e0e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "\n",
    "\n",
    "# Define the kernel\n",
    "def kernel(a, b):\n",
    "    \"\"\" GP squared exponential kernel \"\"\"\n",
    "    kernelParameter = 0.1\n",
    "    sqdist = np.sum(a**2,1).reshape(-1,1) + np.sum(b**2,1) - 2*np.dot(a, b.T)\n",
    "    return np.exp(-.5 * (1/kernelParameter) * sqdist)\n",
    "\n",
    "\n",
    "X = np.random.uniform(-5, 5, size=(5,1))\n",
    "# print(X)\n",
    "print(np.sum(X**2,1).reshape(-1,1)+np.sum(X**2,1))\n",
    "print(np.sum(X**2,1))\n",
    "\n",
    "# K = kernel(X, X)\n",
    "# print(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf9df07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def kernel_torch(a, b):\n",
    "    \"\"\" GP squared exponential kernel \"\"\"\n",
    "    kernelParameter = 0.1\n",
    "    sqdist = torch.cdist(a,b)**2\n",
    "    return torch.exp(-.5 * (1/kernelParameter) * sqdist)\n",
    "\n",
    "N = 10         # number of training points.\n",
    "s = 0.00005    # noise variance.\n",
    "\n",
    "X = torch.FloatTensor(N, 1).uniform_(-5, 5)\n",
    "y = torch.sin(X * (2 * math.pi)) + torch.randn(N)\n",
    "\n",
    "K = kernel_torch(X, X)\n",
    "\n",
    "L = torch.linalg.cholesky(K + s*np.eye(N))\n",
    "alpha = torch.inverse(L.T) @ (torch.inverse(L) @ y.double())\n",
    "\n",
    "f_star = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276eda1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ff84f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8789377e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9fad64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0f04cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefcbe38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b208f26f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5fb539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "478863c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 50)\n",
      "[2.45206211e-03 4.29396716e-02 2.94619400e-01 7.90202733e-01\n",
      " 9.96838443e-01 9.98906071e-01 9.78325265e-01 9.99923784e-01\n",
      " 9.96498488e-01 8.97312070e-01 4.14885406e-01 7.75375059e-02\n",
      " 5.83799840e-03 1.81807952e-04 2.38877794e-06 1.34058097e-08\n",
      " 3.23719907e-11 3.11618315e-12 1.61065874e-09 3.65598953e-07\n",
      " 3.60083901e-05 1.53475326e-03 2.81352184e-02 2.19021139e-01\n",
      " 7.10902734e-01 9.99902911e-01 9.37489849e-01 9.98422267e-01\n",
      " 9.83051560e-01 9.99703404e-01 9.88308549e-01 7.13228142e-01\n",
      " 2.57540649e-01 2.51860749e-01 7.17974504e-01 9.95258224e-01\n",
      " 6.00648254e-01 1.57591075e-01 1.79754297e-02 8.92435361e-04\n",
      " 1.02488115e-04 2.86854795e-03 4.29551158e-02 2.79662087e-01\n",
      " 7.91572991e-01 9.74062910e-01 5.21100766e-01 1.21197896e-01\n",
      " 1.22548251e-02 5.38713451e-04]\n",
      "(50,)\n",
      "(50, 50)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "\n",
    "\"\"\" This is code for simple GP regression. It assumes a zero mean GP Prior \"\"\"\n",
    "\n",
    "\n",
    "# This is the true unknown function we are trying to approximate\n",
    "f = lambda x: np.sin(0.9*x).flatten()\n",
    "#f = lambda x: (0.25*(x**2)).flatten()\n",
    "\n",
    "\n",
    "# Define the kernel\n",
    "def kernel(a, b):\n",
    "    \"\"\" GP squared exponential kernel \"\"\"\n",
    "    kernelParameter = 0.1\n",
    "    sqdist = np.sum(a**2,1).reshape(-1,1) + np.sum(b**2,1) - 2*np.dot(a, b.T)\n",
    "    return np.exp(-.5 * (1/kernelParameter) * sqdist)\n",
    "\n",
    "N = 10         # number of training points.\n",
    "n = 50         # number of test points.\n",
    "s = 0.00005    # noise variance.\n",
    "\n",
    "# Sample some input points and noisy versions of the function evaluated at\n",
    "# these points. \n",
    "X = np.random.uniform(-5, 5, size=(N,1))\n",
    "y = f(X) + s*np.random.randn(N)\n",
    "\n",
    "K = kernel(X, X)\n",
    "L = np.linalg.cholesky(K + s*np.eye(N))\n",
    "\n",
    "# points we're going to make predictions at.\n",
    "Xtest = np.linspace(-5, 5, n).reshape(-1,1)\n",
    "\n",
    "# compute the mean at our test points.\n",
    "K_star = kernel(X, Xtest)\n",
    "K_starstar = kernel(Xtest, Xtest)\n",
    "\n",
    "# implementation based on algo 15.1\n",
    "alpha = np.linalg.solve(L.T, np.linalg.solve(L, y)) \n",
    "f_star = np.dot(K_star.T, alpha)\n",
    "\n",
    "# more efficient implementation?\n",
    "Lk = np.linalg.solve(L, K_star)\n",
    "mu = np.dot(Lk.T, np.linalg.solve(L, y))\n",
    "\n",
    "# compute the variance at our test points.\n",
    "s2 = np.diag(K_starstar) - np.sum(Lk**2, axis=0)\n",
    "s = np.sqrt(s2)\n",
    "\n",
    "print((Lk**2).shape)\n",
    "print(np.sum(Lk**2, axis=0))\n",
    "\n",
    "var = K_starstar - np.dot(Lk.T,Lk)\n",
    "\n",
    "# print(f_star[:10])\n",
    "# print(mu[:10])\n",
    "print(s.shape)\n",
    "print(var.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ad90c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PLOTS:\n",
    "pl.figure(1)\n",
    "pl.clf()\n",
    "pl.plot(X, y, 'r+', ms=20)\n",
    "pl.plot(Xtest, f(Xtest), 'b-')\n",
    "pl.gca().fill_between(Xtest.flat, mu-3*s, mu+3*s, color=\"#dddddd\")\n",
    "pl.plot(Xtest, mu, 'r--', lw=2)\n",
    "pl.savefig('predictive.png', bbox_inches='tight')\n",
    "pl.title('Mean predictions plus 3 st.deviations')\n",
    "pl.axis([-5, 5, -3, 3])\n",
    "\n",
    "# draw samples from the prior at our test points.\n",
    "L = np.linalg.cholesky(K_starstar + 1e-6*np.eye(n))\n",
    "f_prior = np.dot(L, np.random.normal(size=(n,10)))\n",
    "pl.figure(2)\n",
    "pl.clf()\n",
    "pl.plot(Xtest, f_prior)\n",
    "pl.title('Ten samples from the GP prior')\n",
    "pl.axis([-5, 5, -3, 3])\n",
    "pl.savefig('prior.png', bbox_inches='tight')\n",
    "\n",
    "# draw samples from the posterior at our test points.\n",
    "L = np.linalg.cholesky(K_starstar + 1e-6*np.eye(n) - np.dot(Lk.T, Lk))\n",
    "f_post = mu.reshape(-1,1) + np.dot(L, np.random.normal(size=(n,10)))\n",
    "pl.figure(3)\n",
    "pl.clf()\n",
    "pl.plot(Xtest, f_post)\n",
    "pl.title('Ten samples from the GP posterior')\n",
    "pl.axis([-5, 5, -3, 3])\n",
    "pl.savefig('post.png', bbox_inches='tight')\n",
    "\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df87c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
