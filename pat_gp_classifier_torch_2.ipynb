{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb4221d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d34cd980",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.linspace(0, 1, 10)\n",
    "train_y = torch.sign(torch.cos(train_x * (4 * math.pi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7d7279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.models import AbstractVariationalGP\n",
    "from gpytorch.variational import CholeskyVariationalDistribution\n",
    "from gpytorch.variational import VariationalStrategy\n",
    "\n",
    "\n",
    "class GPClassificationModel(AbstractVariationalGP):\n",
    "    def __init__(self, train_x):\n",
    "        variational_distribution = CholeskyVariationalDistribution(train_x.size(0))\n",
    "        variational_strategy = VariationalStrategy(self, train_x, variational_distribution)\n",
    "        super(GPClassificationModel, self).__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        latent_pred = gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "        return latent_pred\n",
    "\n",
    "\n",
    "# Initialize model and likelihood\n",
    "model = GPClassificationModel(train_x)\n",
    "likelihood = gpytorch.likelihoods.BernoulliLikelihood()\n",
    "# likelihood = gpytorch.likelihoods.GaussianLikelihood()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "223187e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/50 - Loss: 0.908\n",
      "Iter 2/50 - Loss: 0.840\n",
      "Iter 3/50 - Loss: 0.797\n",
      "Iter 4/50 - Loss: 0.790\n",
      "Iter 5/50 - Loss: 0.787\n",
      "Iter 6/50 - Loss: 0.780\n",
      "Iter 7/50 - Loss: 0.774\n",
      "Iter 8/50 - Loss: 0.768\n",
      "Iter 9/50 - Loss: 0.764\n",
      "Iter 10/50 - Loss: 0.759\n",
      "Iter 11/50 - Loss: 0.752\n",
      "Iter 12/50 - Loss: 0.746\n",
      "Iter 13/50 - Loss: 0.742\n",
      "Iter 14/50 - Loss: 0.739\n",
      "Iter 15/50 - Loss: 0.738\n",
      "Iter 16/50 - Loss: 0.735\n",
      "Iter 17/50 - Loss: 0.731\n",
      "Iter 18/50 - Loss: 0.727\n",
      "Iter 19/50 - Loss: 0.725\n",
      "Iter 20/50 - Loss: 0.723\n",
      "Iter 21/50 - Loss: 0.721\n",
      "Iter 22/50 - Loss: 0.719\n",
      "Iter 23/50 - Loss: 0.716\n",
      "Iter 24/50 - Loss: 0.714\n",
      "Iter 25/50 - Loss: 0.712\n",
      "Iter 26/50 - Loss: 0.710\n",
      "Iter 27/50 - Loss: 0.709\n",
      "Iter 28/50 - Loss: 0.707\n",
      "Iter 29/50 - Loss: 0.705\n",
      "Iter 30/50 - Loss: 0.703\n",
      "Iter 31/50 - Loss: 0.702\n",
      "Iter 32/50 - Loss: 0.701\n",
      "Iter 33/50 - Loss: 0.699\n",
      "Iter 34/50 - Loss: 0.698\n",
      "Iter 35/50 - Loss: 0.697\n",
      "Iter 36/50 - Loss: 0.696\n",
      "Iter 37/50 - Loss: 0.695\n",
      "Iter 38/50 - Loss: 0.694\n",
      "Iter 39/50 - Loss: 0.693\n",
      "Iter 40/50 - Loss: 0.692\n",
      "Iter 41/50 - Loss: 0.691\n",
      "Iter 42/50 - Loss: 0.691\n",
      "Iter 43/50 - Loss: 0.690\n",
      "Iter 44/50 - Loss: 0.689\n",
      "Iter 45/50 - Loss: 0.688\n",
      "Iter 46/50 - Loss: 0.688\n",
      "Iter 47/50 - Loss: 0.687\n",
      "Iter 48/50 - Loss: 0.687\n",
      "Iter 49/50 - Loss: 0.686\n",
      "Iter 50/50 - Loss: 0.686\n"
     ]
    }
   ],
   "source": [
    "from gpytorch.mlls.variational_elbo import VariationalELBO\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "# num_data refers to the amount of training data\n",
    "mll = VariationalELBO(likelihood, model, train_y.numel())\n",
    "\n",
    "training_iter = 50\n",
    "for i in range(training_iter):\n",
    "    # Zero backpropped gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Get predictive output\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iter, loss.item()))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d18b7ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Go into eval mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Test x are regularly spaced by 0.01 0,1 inclusive\n",
    "    test_x = torch.linspace(0, 1, 101)\n",
    "    # Get classification predictions\n",
    "    observed_pred = likelihood(model(test_x))\n",
    "\n",
    "    # Initialize fig and axes for plot\n",
    "    f, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    ax.plot(train_x.numpy(), train_y.numpy(), 'k*')\n",
    "    # Get the predicted labels (probabilites of belonging to the positive class)\n",
    "    # Transform these probabilities to be 0/1 labels\n",
    "    pred_labels = observed_pred.mean.ge(0.5).float().mul(2).sub(1)\n",
    "    ax.plot(test_x.numpy(), pred_labels.numpy(), 'b')\n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.legend(['Observed Data', 'Mean', 'Confidence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd552d46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
